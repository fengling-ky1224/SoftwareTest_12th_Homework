import os
import matplotlib.pyplot as plt
import numpy as np

# 假设这是从日志中提取的损失值
train_loss = [
        0.5001018012457705,  # Epoch 1
        0.3854763238353932,  # Epoch 2
        0.3305329179510157,  # Epoch 3
        0.30260260339747086, # Epoch 4
        0.2857331001061074,  # Epoch 5
        0.2758880985227037,  # Epoch 6
        0.2660351885443038,  # Epoch 7
        0.2584855724522408,  # Epoch 8
        0.2530481439638645,  # Epoch 9
        0.2495473881668233,  # Epoch 10
        0.24684641573657382, # Epoch 11
        0.24239753472044112, # Epoch 12
        0.24053807620038378, # Epoch 13
        0.23733383401277217, # Epoch 14
        0.2350281556235983,  # Epoch 15
        0.23265530898215922, # Epoch 16
        0.23054919486984293, # Epoch 17
        0.22912609545474358, # Epoch 18
        0.22889278004778194, # Epoch 19
        0.2270249110904146,  # Epoch 20
        0.2260846679515027,  # Epoch 21
        0.22391718293124058, # Epoch 22
        0.22325063877283258, # Epoch 23
        0.22220790639836738, # Epoch 24
        0.2215853419075621,  # Epoch 25
        0.22081392274257985, # Epoch 26
        0.21925724107534328, # Epoch 27
        0.21900326552543234, # Epoch 28
        0.21760494927776622, # Epoch 29
        0.21677133393414477, # Epoch 30
        0.21604045908501807, # Epoch 31
        0.21529833560294293, # Epoch 32
        0.2147598035157995,  # Epoch 33
        0.21405561030545134, # Epoch 34
        0.21323503236821356, # Epoch 35
        0.212968148132588,   # Epoch 36
        0.21075024170444367, # Epoch 37
        0.21017878027038372, # Epoch 38
        0.20940948341121066, # Epoch 39
        0.20937812423452418, # Epoch 40
        0.20875711279346587, # Epoch 41
        0.2071435958781141,  # Epoch 42
        0.20769290023661674, # Epoch 43
        0.20772634747814625, # Epoch 44
        0.20663042842073642, # Epoch 45
        0.20543813356693755, # Epoch 46
        0.20512858477044613, # Epoch 47
        0.2047638401706168,  # Epoch 48
        0.20422272019563836, # Epoch 49
        0.20218957873417975, # Epoch 50
        0.20281830984861293, # Epoch 51
        0.20235848601194137, # Epoch 52
        0.2018205794565221,  # Epoch 53
        0.2013694983213506,  # Epoch 54
        0.20036428239434323, # Epoch 55
        0.2007442184109637,  # Epoch 56
        0.20061049657933255, # Epoch 57
        0.1993067280409184,  # Epoch 58
        0.19938951825841944, # Epoch 59
        0.19776952884932783, # Epoch 60
        0.19750766257973426, # Epoch 61
        0.1980353407561779,  # Epoch 62
        0.19717883849714665, # Epoch 63
        0.19673165132073647, # Epoch 64
        0.19663046300411224, # Epoch 65
        0.1967255950291106,  # Epoch 66
        0.1963088039229525,  # Epoch 67
        0.19578656213397674, # Epoch 68
        0.1948200060015029,  # Epoch 69
        0.1952370689745913,  # Epoch 70
        0.19493226588089416, # Epoch 71
        0.194138950331414,   # Epoch 72
        0.19416548089778168, # Epoch 73
        0.19367871084745894, # Epoch 74
        0.1928011490468015,  # Epoch 75
        0.1935095007907837,  # Epoch 76
        0.1925776405061813,  # Epoch 77
        0.1915654254720566,  # Epoch 78
        0.1916217828526142,  # Epoch 79
        0.19120379489787082, # Epoch 80
        0.19067203182172268, # Epoch 81
        0.19002398800976733, # Epoch 82
        0.1897792084578504,  # Epoch 83
        0.18976389093601959, # Epoch 84
        0.1892954816526555,  # Epoch 85
        0.18989812971112577, # Epoch 86
        0.1894691118851621,  # Epoch 87
        0.18980029486912361, # Epoch 88
        0.18920172988734346, # Epoch 89
        0.1882536271785168,  # Epoch 90
        0.18783659511741171, # Epoch 91
        0.18886194766518918, # Epoch 92
        0.188645037961133,   # Epoch 93
        0.1881702424997979,  # Epoch 94
        0.18723321547533603, # Epoch 95
        0.18791614591758302, # Epoch 96
        0.1869834912742706,  # Epoch 97
        0.18749633946634353, # Epoch 98
        0.18768050371015327, # Epoch 99
        0.18741145254449643  # Epoch 100
]
val_loss = [
        0.4095723084781481,   # Epoch 1
        0.478613283323205,    # Epoch 2
        0.2599391963170922,   # Epoch 3
        0.2734531695428102,   # Epoch 4
        0.22035905783591064,  # Epoch 5
        0.23470302444437277,  # Epoch 6
        0.23720718725867893,  # Epoch 7
        0.2139584305493728,   # Epoch 8
        0.20385617471259573,  # Epoch 9
        0.22086829854094464,  # Epoch 10
        0.21448343927445618,  # Epoch 11
        0.21293307063372238,  # Epoch 12
        0.20163416020248248,  # Epoch 13
        0.18610981948997662,  # Epoch 14
        0.17486072266879288,  # Epoch 15
        0.1736481150855189,   # Epoch 16
        0.1787570212846217,   # Epoch 17
        0.21810447554225507,  # Epoch 18
        0.16799194236164508,  # Epoch 19
        0.1737678695632064,   # Epoch 20
        0.17686372768619787,  # Epoch 21
        0.1937688009246536,   # Epoch 22
        0.17762456834316254,  # Epoch 23
        0.21489008094953455,  # Epoch 24
        0.16392686153235642,  # Epoch 25
        0.16661760275778564,  # Epoch 26
        0.16268333274385202,  # Epoch 27
        0.18028618492510007,  # Epoch 28
        0.15965743654448053,  # Epoch 29
        0.17310844588538873,  # Epoch 30
        0.16162304094304208,  # Epoch 31
        0.1602434143424034,   # Epoch 32
        0.15893400978782904,  # Epoch 33
        0.1662734951014104,   # Epoch 34
        0.16183214148749475,  # Epoch 35
        0.1726314004348672,   # Epoch 36
        0.16753009058859036,  # Epoch 37
        0.2040914190204247,   # Epoch 38
        0.16277107013308484,  # Epoch 39
        0.207456202286741,    # Epoch 40
        0.15748457610607147,  # Epoch 41
        0.20364063589469247,  # Epoch 42
        0.1752702713660572,   # Epoch 43
        0.16416789461737094,  # Epoch 44
        0.16118879745835843,  # Epoch 45
        0.17835011300833328,  # Epoch 46
        0.16310359926327414,  # Epoch 47
        0.1701008609455565,   # Epoch 48
        0.15789953684029373,  # Epoch 49
        0.1909733719151953,   # Epoch 50
        0.167665285260781,    # Epoch 51
        0.16282772888307986,  # Epoch 52
        0.15773366424052612,  # Epoch 53
        0.15715106123167535,  # Epoch 54
        0.15752218631298645,  # Epoch 55
        0.1613011065384616,   # Epoch 56
        0.15289213152035422,  # Epoch 57
        0.15576339156731314,  # Epoch 58
        0.16566223942715189,  # Epoch 59
        0.15541877144056818,  # Epoch 60
        0.15307062896697418,  # Epoch 61
        0.15633937522121097,  # Epoch 62
        0.15865847597951474,  # Epoch 63
        0.15170025145230087,  # Epoch 64
        0.15197080535733182,  # Epoch 65
        0.15386729978996774,  # Epoch 66
        0.15699493658283484,  # Epoch 67
        0.15411828199158545,  # Epoch 68
        0.16092102974653244,  # Epoch 69
        0.15694429887377698,  # Epoch 70
        0.1544910332430964,   # Epoch 71
        0.15418260414963184,  # Epoch 72
        0.1533488858005275,   # Epoch 73
        0.1584852509524511,   # Epoch 74
        0.1534712726007337,   # Epoch 75
        0.14927556203759235,  # Epoch 76
        0.15267547705899115,  # Epoch 77
        0.15222057376218878,  # Epoch 78
        0.15130257023417432,  # Epoch 79
        0.15064413100481033,  # Epoch 80
        0.15036033482655234,  # Epoch 81
        0.14850223388360895,  # Epoch 82
        0.14903619302355725,  # Epoch 83
        0.14905629436606946,  # Epoch 84
        0.14847405902717425,  # Epoch 85
        0.14835568549840347,  # Epoch 86
        0.14822282415369284,  # Epoch 87
        0.14841415247191553,  # Epoch 88
        0.14784419990104178,  # Epoch 89
        0.14783042474933292,  # Epoch 90
        0.14785005184619324,  # Epoch 91
        0.14762663873641388,  # Epoch 92
        0.1474109055555385,   # Epoch 93
        0.14765847215185995,  # Epoch 94
        0.14744316851315292,  # Epoch 95
        0.14746359865302625,  # Epoch 96
        0.147337576293427,    # Epoch 97
        0.14742912060540656,  # Epoch 98
        0.14746725753597592,  # Epoch 99
        0.14747280173975488   # Epoch 100
]
# 确保损失列表长度一致（根据实际数据调整）
min_len = min(len(train_loss), len(val_loss))
train_loss = train_loss[:min_len]
val_loss = val_loss[:min_len]

# 创建 plots 目录（如果不存在）
os.makedirs("plots", exist_ok=True)

# 绘制学习曲线
plt.figure(figsize=(10, 6))
plt.plot(train_loss, label="Training Loss", color="blue")
plt.plot(val_loss, label="Validation Loss", color="red")
plt.title("AttUnet-ISIC Training and Validation Loss")
plt.xlabel("Epoch")
plt.ylabel("Loss")
plt.legend()
plt.grid(True)

# 保存图像
plt.savefig("plots/isic_loss_plot.png")
plt.close()

print("学习曲线已保存到 plots/plot.png")